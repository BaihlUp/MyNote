---
title: AI 大模型应用开发实战
date: 2023-12-23
categories:
  - 人工智能&大数据
tags:
  - 人工智能
  - 大模型
published: false
---
# 0 参考资料

- 《AI 大模型应用开发实战》项目地址：[https://github.com/DjangoPeng/openai-quickstart](https://github.com/DjangoPeng/openai-quickstart)

## 0.1 常用链接

token数量计算工具tokenizer：[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)

## 0.2 技术栈

![|500](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240207160957.png)

# 1 大模型初探

## 1.1 GPT 和 BERT

- 差异
![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312250939222.png)


- 共识

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312250940010.png)


## 1.2 NLP语言模型发展一览

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312250941421.png)


## 1.3 GPT-1 到 GPT-3

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312250944732.png)

### 1.3.1 3个关键概念

**In-Context Learning：** 在上下文中学习指的是大型语言模型如GPT-3的一种能力，即在给定的上下文中使用新的输入来改善模型的输出。这种学习方式并不涉及到梯度更新或微调模型的参数，而是通过提供一些具有特定格式或结构的示例输人，使模型能够在生成输出时利用这些信息。例如，如果你在对话中包含一些英法翻译的例子，然后问模型一个新的翻译问题，模型可能会根据你提供的上下文示例生成正确的翻译。

**Few-Shot Learning：** 少样本学习是指用极少量的标注样本来训练机器学习模型的技术。在GPT-3的案例中，少样本学习的实现方式是向模型提供少量的输人-输出对示例，这些示例作为对话的部分，描述了模型应该执行的任务。然后，模型会生成一个输出，该输出是对与示例类似的新输人的响应。例如，你可以给模型提供几个英法翻译的例子，然后给出一个新的英文单词让模型翻译，模型会尝试产生一个正确的翻译。

**Prompt Engineering：** 提示工程是指设计和优化模型的输入提示以改善模型的输出，在大型语言模型中，如何提问或构造输入的方式可能对模型的输出有重大影响。因此，选择正确的提示对于获取有用的输出至关重要。例如，为了让GPT-3生成一个诗歌，你可能需要提供一个详细的、引导性的提示，如“写一首关于春天的十四行诗”，而不仅仅是“写诗”。

## 1.4 ChatGPT

### 1.4.1 Pre-Tranined LM + Fine-Tuning 范式
![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312250953598.png)

### 1.4.2 OpenAI 的模型迭代：预训练与微调

在 GPT 模型的演进过程中，OpenAl 采用了一系列的训练策略，这包括基础的大规模预训练，也包括后续的指令微调等方法。这两种策略在模型的训练过程中起到了不同的作用。
- **预训练(Pre-Trained)：** 大规模预训练是为了使模型获取丰富的语言知识和理解能力。在预训练过程中，模型通过大量的无标签数据来学习语言的基础知识，这一过程主要是依赖无监督学习的。
- **指令微调（Instruction-Tuning）：** 在预训练模型的基础上，通过针对特定任务的标注数据进行微调能够使模型在特定任务上的表现得到提升。同时，通过对微调数据的精心设计和选择，还能够引导模型按照人类的预期来执行任务。这一过程主要依赖有监督学习。

在这个过程中，预训练和微调是相辅相成的。预训练为模型提供了丰富的语言知识，而微调则利用这些知识来解决特定的任务。然而，微调的数据量通常比预训练的数据量要少得多，因此微调的主要作用并不是为模型注入新的知识，而是激发和引导模型利用已有的知识来完成特定任务。

在GPT模型的演进过程中，OpenAl还探索了多种微调策略，例如GPT-3.5的分化技能树等。这些微调策略能够帮助模型在不同的任务上表现得更好，同时也使模型的输出更符合人类的预期。

此外，OpenAl还注意到，模型在进行微调时可能会出现一些问题，例如数据稀疏性、灾难遗忘、资源浪费和通用性差等。为了解决这些问题，OpenAl提出了一种新的训练策略，即提示学习。通过设计提示信息，可以激发预训练大模型的能力，从而提高模型在具体任务上的表现。

### 1.4.3 初代 GPT-3.5：code-davinci-002

初代GPT-3.5系列 (以下简称新模型) 相比 GPT-3 系列模型，具有以下优点:
- **人类指令响应(Responding to Human nstructions):** 新模型能针对特定指今生成更恰当的回应，而非回复训练集中频繁出现的无关句子。
- **任务泛化能力(Task Generalization):** 当新模型接收大量指今调整后，能自动适应并有效回答未见过的新指令，这在应对用户不断变化的问题上至关重要。
- **代码理解与生成(Code Understanding and Generation):** 经过代码训练的新模型能理解并生成代码，强化了编程相关应用的能力。
- **复杂推理的思维链(Chain of Thought for Complex Reasoning):** 新模型已提高思维推理能力使其能处理需要多步推理的问题，这可能是突破模型缩放法则(scaling aws)限制，实现真正的突现性能力的关键。

在基础模型 code-davinci-002 上指令微调后得到了 text-davinci-002，它在以下数据作了微调: 
- 人工标注的指令和期待的输出; 
- 由人工标注者选择的模型输出。

### 1.4.4 ChatGPT 是技术和商业的成功结合

1. **模型训练:** 虽然GPT-3和ChatGPT都是基于Transformer的语言模型，但在训练数据和目标函数上有所不同。GPT-3主要是用大量的非结构化文本进行训练的，而ChatGPT则在GPT-3的基础上进行了进一步的训练，这包括使用与对话相关的数据集和更适合对话任务的训练目标。
2. **对话管理:** ChatGPT在对话管理方面进行了优化，以提供更自然、连贯的对话体验。这包括保2持对话的上下文、处理多轮对话、以及在一个对话中处理多个话题等。
3. **用户输入处理:** ChatGPT也进行了优化以更好地处理用户的输入，这包括理解和响应各种类型3.的查询，如信息查询、任务请求、小说式的输入等
4. **输出生成:** ChatGPT进行了一些优化以生成更贴近人类的输出。这包括使用更复杂的生成策略、生成更长的响应、以及更好地处理模糊或不确定的输入等
5. **安全性和道德规节:** ChatGPT还进行了一些改进以提高模型的安全性和符合道德规范。这包括对模型的过滤和调节，以防止生成不适当或有害的内容，以及对模型进行额外的评估和测试.以确保其在各种情况下都能表现良好。

### 1.4.5 GPT 家族技术迭代与改进

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251001352.png)

## 1.5 GPT-4 
### 1.5.1 GPT-4 介绍视频

[GPT-4介绍视频](https://www.ign.com.cn/tech/43173/video/gpt-4jie-shao-shi-pin)

### 1.5.2 GPT-4：多模态开启 LLM-native 应用时代

2022年8月，GPT-4 模型训练完成。2023年3月14日，OpenAl 正式发布 GPT-4。与GPT-3和GPT-3.5相比GPT-4在各方面都有所优化和提升:
1. **多模态模型：** GPT-4支持图像输入，出色的视觉信息理解能力使得GPT-4能对接更多样化的下游任务如:描述不寻常图像中的幽默、总结截屏文本以及回答包含图表的试题。在文本理解能力上，GPT-4 在中文和多轮对话中也表现出远超 GPT-3.5 的能力。
2. **扩展上下文窗日：** gpt-4 and gpt-4-32k 分别提供了最大长度为8192和32768个token的上下文窗口，这使得2GPT-4可以通过更多的上下文来完成更复杂的任务，也为 思维链 (COT) 、思维树TOT) 等后续工作提供了可能。
3. **GPT+生态：** 借助GPT-4强大能力，依托 ChatGPT Plugin 搭建AIGC应用生态商店 (类似 App Store)3。
4. **应用+GPT：** GPT-4已经被应用在多个领域，包括微软Office、Duolingo、Khan Academy等。

# 2 提示学习

## 2.1 Prompt Learning vs In-context Learning

- **Prompt learning** 是一种使用预训练语言模型的方法，它不会修改模型的权重。在这种方法中
模型被给予一个提示 (prompt) ，这个提示是模型输人的一部分，它指导模型产生特定类型的输出。这个过程不涉及到对模型权重的修改，而是利用了模型在预训练阶段学习到的知识和能力。
- **In-context learning** 是指模型在处理一系列输入时，使用前面的输入和输出作为后续输入的上下文，这是Transformer模型 (如GPT系列) 的一种基本特性，例如，当模型在处理一个对话任务时它会使用对话中的前几轮内容作为上下文，来生成下一轮的回答。这个过程也不涉及到对模型权重的修改。

总的来说，promptlearning和in-context learning都是利用预训练语言模型的方法，它们都不会修改模型的权重，它们的主要区别在于，prompt learning关注的是如何通过设计有效的提示来**引导模型的输出**，而in-context learning则关注的是如何**利用输入序列中的上下文信息**来影响模型的输出。

## 2.2 Prompt Learning vs Prompt Tuning

Promptlearning和prompt tuning都是自然语言处理(NLP)中的概念，它们都与如何使用和优化预训练语言模型 (例如GPT-3或GPT-4) 有关
- **Prompt learning:** 是一种方法，其中模型被训练以响应特定的提示 (prompt) ，在这种情况下提示是模型输人的一部分，它指导模型产生特定类型的输出，例如，如果你向模型提供了"Translatethe following English text to French: texty"这样的提示，模型就会学习到这是一个翻译任务，并尝试将itext从英语翻译成法语。这种方法的关键在于找到能够引导模型正确响应的有效提示。
- **Prompt tuning**，又称为"prompt engineering"，是一种优化技术，它涉及到寻找或生成能够最大限度提高模型性能的提示。这可能涉及到使用启发式方法、人工智能搜索算法，或者其至是人工选择和优化提示。Prompt tuning的目标是找到一种方式，使得当给定这个提示时，模型能够生成最准确、最相关的输出。

总的来说，promptlearning和prompt tuning都与如何使用和优化模型的输入提示有关。它们的主要区别在干，oromot learning更关注于如何训练模型以响应特定的提示，而orompt tuning则更关注于如何找到或生成最优的提示以提高模型的性能。

## 2.3 思维链（Chain-of-Thought，CoT）

**CoT Prompting** 作为一种促进语言模型推理的方法具有几个吸引人的特点：
- 首先，从原则上讲，COT 允许模型将多步问题分解为中间步骤，这意味着可以将额外计算资源分配给需要更多推理步骤的问题。
- 其次，COT 提供了对模型行为的可解释窗口，提示了它可能是如何得出特定答案的，并提供了调试
推理路径错误之处的机会 (尽管完全描述支持答案的模型计算仍然是一个未解决问题)
- 第三，在数学应用题、常识推理和符号操作等任务中都可以使用思维链推理 (COT Reasoning)并且在原则上适用于任何人类能够通过语言解决的任务。
- 最后，在足够大规模现成语言模型中很容易引发 COT Reasoning ，只需在少样本提示示例中包含一些连贯思路序列即可。

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251024803.png)

> 通过给大模型指令，通过思维链，得到正确答复。

通过思维链，我们可以看到大语言模型的强与弱
- 它强在，模型规模的提高，让语义理解、符号映射、连贯文本生成等能力跃升，从而让多步骤推理的思维链成为可能，带来“智能涌现”
- 它弱在，即使大语言模型表现出了前所未有的能力，但思维链暴露了它，依然是鹦鹉学舌，而非真的产生了意识。
没有思维链，大模型几乎无法实现逻辑推理
但有了思维链，大语言模型也可能出现错误推理，尤其是非常简单的计算错误。Jason Wei 等的论文中，曾展示过在 GSM8K 的一人子集中，大语言模型出现了 8% 的计算错误，比如6*13=
68 (正确答案是78)

## 2.4 思维树（Tree-of-Thoughts，ToT）

### 2.4.1 示意图

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251026348.png)


### 2.4.2 ToT 工作原理

- Step 1 思维分解

虽然COT样本以连贯的方式呈现思维，没有明确的分解过程，但TOT利用问题属性来设计和分解中间思维步骤。如下表所示，根据不同的问题，一个思维可以是几个词 (填字游戏)，一行方程式 (24点游戏) ，或者是整段写作计划 (创意写作)。
总体而言，一个思维应该足够“小”，以便语言模型能够生成有前景且多样化的样本 (例如生成整本书通常太“大”而无法连贯) ，同时又足够“大”，以便语言模型能够评估其对于问题求解的前景 (例如仅生成一个标记通常太“小”无法评估) 。

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251029809.png)

- Step 2 思维生成

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251029554.png)

- Step 3 状态评估

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251030981.png)

> 对于这两种策略，我们可以多次提示语言模型来聚合值或投票结果，以换取更忠实/稳健的启发式方法所需的时间/资源/成本

- Step 4 搜索算法

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251031455.png)

# 3 大模型开发基础：Embedding

基于深度学习的语言模型：一种基于深度学习的自然语言处理技术被用于表示文字，包括汉字。这种技术将每个字或词映射到一个高维向量（称为词嵌入），这个向量可以捕捉到字或词的语义信息。
## 3.1 表示学习与嵌入

表示学习（Representation Learning）和嵌入（Embedding）是密切相关的概念，它们可以被视为在不同领域中对同一概念的不同命名或描述。
- **表示学习：** 通过学习算法自动地从原始数据中学习到一种表示形式或特征表示，该表示形式能够更好地表达数据的重要特征和结构。表示学习的目标是将输人数据转换为具有良好表示能力的特征空间，使得在该空间中的数据具有更好的可分性、可解释性或推理能力
- **嵌人：** 表示学习的一种形式，通常用于将高维数据映射到低维空间中的表示形式。嵌入可以是词嵌入、图像嵌入、图嵌入等。例如，在自然语言处理中，词嵌入将词语映射到低维向量空间，以捕捉词语之间的语义和句法关系。在图像处理中，图像嵌入将图像映射到低维向量空间，以表示图像的视觉特征。

因此，嵌入可以被视为一种表示学习的特定形式，旨在将高维数据转换为低维向量表示。表示学习可以涉及更广泛的概念和方法，包括嵌入在内，以实现对数据的更好理解和表达。

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251037464.png)

## 3.2 表示学习怎么学？

**表示学习(Representation Learning)** 是指通过学习算法自动地从原始数据中学习到一种表示形式或特征表示，该表示形式能够更好地表达数据的重要特征和结构。表示学习的目标是将输入数据转换为具有良好表示能力的特征空间，使得在该空间中的数据具有更好的可分性、可解释性或推理能力。
- **可分性：** 表示学习的目标之一是将输入数据转换为具有更好可分性的特征空间。这意味着在学习到的表示中，不同类别或不同概念之间的样本应该有明显的边界或区别。例如，在图像分类任务中，表示学习的目标是使来自不同类别的图像在特征空间中更容易区分。这样的特征表示使得机器学习算法可以更轻松地进行分类、聚类或其他数据分析任务。
- **可解释性：** 另一个表示学习的目标是生成可解释性的特征表示。这意味着学习到的特征应该具有对应于原始数据中的可理解概念或语义的含义。例如，在自然语言处理中，词嵌入模型学习到的词向量应该能够捕捉到词语之间的语义关系，使得相似的词在向量空间中更接近。这样的表示不仅有助于模型的解释性，也可以在语义分析和文本生成等任务中提供更好的性能。
- **推理能力：** 另一个重要的目标是使得学习到的特征表示在推理任务中更具能力。这意味着在特征空间中，我们可以执行类似于推理、类比或关联的操作。例如，通过在词嵌入空间中执行向量运算，如"国王"."男人"+"女人"，我们可以得到与"皇后"非常接近的结果，这种推理能力使得我们能够进行关联和类比推理，从而在自然语言处理、推荐系统和知识图谱等领域中实现更高级的语义推理和理解。

> 深度神经网络（DNN）：一种高效学习数据抽象特征表示的方法

## 3.3 维度太高，怎么知道学会了？

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251045261.png)

### 3.3.1 嵌入（Embedding）的价值

1. **降维：** 在许多实际问题中，原始数据的维度往往非常高。例如，在自然语言处理中，如果使用One-hot编码来表示词汇，其维度等于词汇表的大小，可能达到数十万甚至更高。通过Embedding，我们可以将这些高维数据映射到一个低维空间，大大减少了模型的复杂度。
2. **捕捉语义信息：** Embedding不仅仅是降维，更重要的是，它能够捕捉到数据的语义信息。例如，在词嵌入中，语义上相近的词在向量空间中也会相近。这意味着Embedding可以保留并利用原始数据的一些重要信息。
3. **适应性：** 与一些传统的特征提取方法相比，Embedding是通过数据驱动的方式学习的。这意味着它能够自动适应数据的特性，而无需人工设计特征。
4. **泛化能力：** 在实际问题中，我们经常需要处理一些在训练数据中没有出现过的数据。由于Embedding能够捕捉到数据的一些内在规律，因此对于这些未见过的数据，Embedding仍然能够给出合理的表示。
5. **可解释性：** 尽管Embedding是高维的，但我们可以通过一些可视化工具(如-SNE)来观察和理解Embedding的结构。这对于理解模型的行为，以及发现数据的一些潜在规律是非常有用的。

### 3.3.2 Embedding
嵌入 （Embedding）是表示学习的一种特定形式，旨在将高维数据映射到低维空间中的向量表示

- **词嵌入（Word Embedding）：** 在自然语言处理中，词嵌人将词语映射到低维向量空间，以捕捉词语之间的语义和句法关系。通过学习词嵌人，可以将词语表示为连续的向量，其中相似的词语在向量空间中彼此靠近。它在自然语言处理任务中广泛应用，包括词语相似度计算、文本分类、命名实体识别等。词嵌入可以通过Word2Vec、GloVe 等方法进行学习
- **图像嵌入 (lmage Embedding)：** 在图像处理中，图像嵌入将图像映射到低维向量空间，以表示图像的视觉特征。这种嵌入方法通常通过使用卷积神经网络 (Convolutional Neural Networks,CNN) 等深度学习技术来提取图像的特征表示。
- **图嵌入（Graph Embedding）：** 是用于学习图结构的表示学习方法，将图中的节点和边映射到低维向量空间中，通过学习图嵌入，可以将复杂的图结构转化为向量表示，以捕捉节点之间的结构和关联关系。这些方法可以通过DeepWalk、Node2Vec、GraphSAGE等算法来实现。图嵌入在图分析、社交网络分析、推荐系统等领域中广泛应用于发现社区结构、节点相似性、信息传播等图属性。

> 包括嵌入在内，表示学习涉及更广泛的概念和方法，以实现对数据的更好理解和表达。


### 3.3.3 Word Embedding vs Language Model

- **Word Embedding：** 人通常被用来生成词的向量表示，这过程通常是静态的，即一旦训练完成，每个词的向量表示就确定了。词嵌入的主要目标是捕获单词或短语的语义和语法信息，并将这些信息以向量形式表示出来。词嵌入的一个重要特性是，语义上相近的词在嵌入空间中的距离也比较近。然而，词嵌入并不能理解上下文信息，即相同的词在不同的上下文中可能有不同的含义，但词嵌入无法区分这些含义。
- **Language Model：** 语言模型则是预测词序列的概率模型，这个过程通常是动态的，会根据输入的上下文进行变化。语言模型的主要目标是理解和生成文本。这包括对上下文的理解，词的预测，句子的生成等等。语言模型会用到词嵌入，但同时也会对上下文进行建模，这样可以处理词在不同上下文中的不同含义。

在某种程度上，你可以将词嵌入看作是语言模型的一部分或者输入，语言模型使用词嵌入捕捉的信息，来进行更深层次的语义理解和文本生成，当然，现在有一些更先进的模型，比如BERT，GPT等，它们生成的是上下文相关的词嵌人，即词的嵌入会根据上下文变化，这样一定程度上弥补了传统词嵌入模型的不足。

## 3.4 核心概念 维恩图

![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251058786.png)

## 3.5 OpenAI Embeddings 开发

Embeddings 代码示例：[https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/embedding.ipynb](https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/embedding.ipynb)

> 通过导入 美食评论 数据集，通过 OpenAI Embeddings 处理，查看 处理后的向量结果。


# 4 OpenAI API 

**API 手册：** [https://platform.openai.com/docs/api-reference/](https://platform.openai.com/docs/api-reference/)

## 4.1 Models API

获取当前可用的模型和提供的基本信息：
GET https://api.openai.com/vi/models
```python
import os
from openai import OpenAI
client = OpenAI()

models = client.models.list()
```

检索模型实例：
GET https://api.openai.com/vi/models/{model}
```python
import os
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')
openai.Model.retrieve('text-davinci-003')
```

## 4.2 Completions API

- Chat Completions API

聊天补全API：给定一个包含对话的消息列表，返回模型生成的消息作为输出，尽管聊天格式旨在多轮对话变得简单，但它同样适用于没有任何对话的单轮任务。

```python
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Who won the world series in 2020?"},
    {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
    {"role": "user", "content": "Where was it played?"}
  ]
)
```

```bash
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Who won the world series in 2020?"
      },
      {
        "role": "assistant",
        "content": "The Los Angeles Dodgers won the World Series in 2020."
      },
      {
        "role": "user",
        "content": "Where was it played?"
      }
    ]
  }'
```

使用代码示例：[https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/models.ipynb](https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/models.ipynb)

# 5 GPT 模型实战

## 5.1 技巧与原则

- 角色设定：擅于使用 System 给GPT设定角色和任务，如“哲学大师”
- 指令注入： 在 System 中注入常驻任务指令，如“主题创作”
- 问题拆解： 将复杂问题拆解成的子问题，分步骤执行，如: Debug 和多任务:0
- 分层设计：创作长篇内容，分层提问，先概览再章节，最后补充细节，如: 小说生成
- 编程思维：将prompt当做编程语言，主动设计变量、模板和正文，如: 评估模型输出质量
- Few-Shot： 基于样例的prompt设计，规范推理路径和输出样式，如: 构造训练数据


## 5.2 Playground

Official Playground：[https://platform.openai.com/playground](https://platform.openai.com/playground)

可以使用 Playground 测试自己的 Prompt，通过SYSTEM 指令进行控制：
![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251436690.png)

示例：通过输入文本，让 GPT 模型 生成 QA 问题：
![](https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202312251437021.png)

## 5.3 Function Calling

`functions` 是 Chat Completion API 中的可选参数，用于提供函数定义。其目的是使 GPT 模型能够生成符合所提供定义的函数参数。请注意，API不会实际执行任何函数调用。开发人员需要使用GPT 模型输出来执行函数调用。
如果提供了`functions`参数，默认情况下，GPT 模型将决定在何时适当地使用其中一个函数。
可以通过将`function_call`参数设置为`{"name": "<insert-function-name>"}`来强制 API 使用指定函数。
同时，也支持通过将`function_call`参数设置为`"none"`来强制API不使用任何函数。
如果使用了某个函数，则响应中的输出将包含`"finish_reason": "function_call"`，以及一个具有该函数名称和生成的函数参数的`function_call`对象。

代码示例：[https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/function_call.ipynb](https://github.com/DjangoPeng/openai-quickstart/blob/main/openai_api/function_call.ipynb)
## 5.4 OpenAI-Translator




